### 一、准备

1.安装requests

2.安装bs4 

```python
pip install requests

pip install bs4
```

### 二、目标

1.熟练使用requests请求目标网站

2.掌握使用bs4解析数据

3.了解urlib3

### 三、知识要点

#### 1.requests：让http服务人类

##### 1.1 requests简介

requests是一个很实用的python HTTP客户端库，编写爬虫和测试服务器响应数据时经常会用到。可以说requests完全满足如今网络的需求。

文档API：https://requests.readthedocs.io/en/latest/

##### 1.2 requests简单使用

get请求

ur-->统一资源定位符

Https://www.baidu.com

网络后缀

.com商业机构

.org非盈利组织

.gov

.edu

.cn

.us

#### 2.css选择器：BeautifulSoup4

##### 2.1bs4简介

Beautiful Soup是一个HTML/XML的解析器，主要的功能是解析和提取HTML/XML数据。

**特点：**

1.Beautiful Soup解析时会载入整个文档，解析全部，因此时间和内存开销都会大很多

2.BeautifulSoup用来解析HTML比较简单，API也非常人性化，支持CSS选择器，python标准库中的HTML解析器，也支持lxml的XML解析器。

3.Beautiful Soup3 目前已经停止开发，现在推荐使用Beautiful soup4。使用pip 安装即可：pip install beautifulsoup4或者pip install bs4



##### 2.2 bs4使用

代码演示：

```python
from bs4 import BeautifulSoup
with open('./布局.html','rb') as f:
    html=f.read()
soup=BeautifulSoup(html,'lxml')
print(soup.prettify())#让打印出来的格式更加好看

#下面一种方式也可以打开html
# soup=BeautifulSoup(open('布局.html','rb'))
# print(soup.prettify())
```

如果没有lxml,通常运行会出现一个警告，是因为没有指定解析器，所以默认使用了lxml解析器，如果不想该警告出现，可以通过soup=BeautifulSoup(html,'lxml')指定解析器即可

> 解析器介绍
>
> lxml解析器（推荐使用）
>
> - 优势：速度快，文档容错能力强（C编写），推荐使用
> - 劣势：Python 2.7.3 or 3.2.2前的版本中文档容错能力差
>
> Html.parser
>
> - 优势：Python内置，执行速度适中，文档容错能力强
> - 劣势：Python 2.7.3 or 3.2.2前的版本中文档容错能力差
>
> html5lib
>
> - 优势：最好的容错性，以浏览器的方式解析文档，生成Html5格式的文档
> - 劣势：速度慢，不依赖外部扩展

pip install lxml装一个解析器

#### 2.3 bs4的4种对象

BeautifulSoup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象，所有对象可以归纳为4种：

- Tag
- NavigableString
- BeautifulSoup
- Comment

##### 2.3.1 Tag对象

Tag其实就是HTML中的一个个标签，比如head、title、p等这些HTML标签包裹的内容就是Tag

```python
from bs4 import BeautifulSoup
with open('./Google.html','rb') as f:
    html=f.read()
#创建BeautifulSoup对象，并且指定解析器为lxml
soup=BeautifulSoup(html,'lxml')
#print(soup.prettify())#让打印出来的格式更加好看
#查看head标签
#print(soup.head)

#查看title
print(soup.title)

#查看td标签 列举出第一个符合条件的td标签内容
#print(soup.td)
print(type(soup.title))
```

##### 2.3.2NavigableString对象

NavigableString是HTML的Tag里的String

```python
from bs4 import BeautifulSoup
with open('./Google.html','rb') as f:
    html=f.read()
#创建BeautifulSoup对象，并且指定解析器为lxml
soup=BeautifulSoup(html,'lxml')

#查看title
print(soup.title)

#获取title中的文字
print(soup.title.string)

#查看类型
print(type(soup.title.string))
```

##### 2.3.3BeautifulSoup

是soup对象

```python
from bs4 import BeautifulSoup
with open('./Google.html','rb') as f:
    html=f.read()
#创建BeautifulSoup对象，并且指定解析器为lxml
soup=BeautifulSoup(html,'lxml')
print(soup.name)

print(type(soup))
```

##### 2.3.4 Comment 对象

是注释内容



#### 2.4 CSS选择器

##### 2.4.1通过标签名查找

```python
#查找title标签
print(soup.select('title'))
#查找td标签
print(soup.select('td'))
#查找tr标签
print(soup.select('tr'))
```

2.4.2通过类名查找

2.4.3通过ID名查找

2.4.4 组合查找

2.4.5属性查找

```python
from bs4 import BeautifulSoup
with open('./Google.html','rb') as f:
    html=f.read()
#创建BeautifulSoup对象，并且指定解析器为lxml
soup=BeautifulSoup(html,'lxml')

#标签名
#查看title标签
print(soup.select('title')) #返回一个列表

#通过类名查找,加一个.,查找类名为gb_Jd的标签
#print(soup.select('.gb_Jd'))

#通过ID名查找id为kk的，前面加一个#
#print(soup.select('#kk'))

#组合查找
print(soup.select('div .L3eUgb'))

#属性查找
print(soup.select('div[class="L3eUgb"]'))

#用get_text()来获取内容
```



### 3.了解 urllib3

```python
#导入urllib3
import urllib3
#创建PoolManager实例发起请求
pool=urllib3.PoolManager()
#添加请求头
headers={
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/51.0.2704.79 Safari/537.36 Edge/14.14931'
}
res=pool.request('get',"https://www.google.com/search", fields={'q':'spider'},headers=headers)
print(res.data.decode())
```













